{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ff57973",
   "metadata": {},
   "source": [
    "# Semi-Join with exists() Method in JAXFrame\n",
    "\n",
    "This notebook demonstrates the `exists()` method for performing semi-joins in JAXFrame DataFrames. Semi-joins filter rows from one table based on the existence of matching rows in another table, but only return columns from the first table."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66ba73e",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries\n",
    "\n",
    "Import JAXFrame, JAX, NumPy, and other necessary libraries for testing the semi-join functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6258cc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jaxframe import DataFrame\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from typing import List\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n",
    "print(f\"JAX arrays available: {jnp.array([1, 2, 3])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b01b4e00",
   "metadata": {},
   "source": [
    "## 2. Create Test DataFrames\n",
    "\n",
    "Create sample DataFrames with mixed data types (lists, NumPy arrays, JAX arrays) to test the semi-join implementation across different scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515493d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create customer DataFrame with mixed types\n",
    "customers_data = {\n",
    "    'customer_id': ['C001', 'C002', 'C003', 'C004', 'C005', 'C006'],\n",
    "    'name': ['Alice', 'Bob', 'Charlie', 'David', 'Eve', 'Frank'],\n",
    "    'city': ['New York', 'Los Angeles', 'Chicago', 'Houston', 'Phoenix', 'Philadelphia'],\n",
    "    'age': np.array([25, 30, 35, 28, 32, 45]),\n",
    "    'credit_score': jnp.array([750.0, 680.0, 720.0, 650.0, 800.0, 690.0])\n",
    "}\n",
    "customers = DataFrame(customers_data, name=\"customers\")\n",
    "\n",
    "# Create orders DataFrame - only some customers have orders\n",
    "orders_data = {\n",
    "    'order_id': ['O001', 'O002', 'O003', 'O004', 'O005', 'O006'],\n",
    "    'customer_id': ['C001', 'C001', 'C003', 'C003', 'C005', 'C005'],  # Only C001, C003, C005 have orders\n",
    "    'amount': jnp.array([100.0, 150.0, 200.0, 75.0, 300.0, 250.0]),\n",
    "    'order_date': ['2024-01-01', '2024-01-15', '2024-02-01', '2024-02-10', '2024-03-01', '2024-03-15']\n",
    "}\n",
    "orders = DataFrame(orders_data, name=\"orders\")\n",
    "\n",
    "print(\"Customer DataFrame:\")\n",
    "display(customers.to_pandas())\n",
    "print(f\"\\nCustomer column types: {customers.column_types}\")\n",
    "\n",
    "print(\"\\nOrders DataFrame:\")\n",
    "display(orders.to_pandas())\n",
    "print(f\"\\nOrders column types: {orders.column_types}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6585f6ce",
   "metadata": {},
   "source": [
    "## 3. Implement Basic Semi-Join with exists() Method\n",
    "\n",
    "Implement the exists() method on DataFrame class and demonstrate basic semi-join operations that filter rows based on existence of matches in another DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f146ab87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic semi-join: Find customers who have placed orders\n",
    "customers_with_orders = customers.exists(orders, on='customer_id')\n",
    "\n",
    "print(\"Customers who have placed orders (semi-join):\")\n",
    "display(customers_with_orders.to_pandas())\n",
    "print(f\"\\nResult shape: {customers_with_orders.shape}\")\n",
    "print(f\"Original customers: {len(customers)}, customers with orders: {len(customers_with_orders)}\")\n",
    "print(f\"Column structure preserved: {customers_with_orders.columns == customers.columns}\")\n",
    "\n",
    "# Verify no columns from orders DataFrame were added\n",
    "assert 'order_id' not in customers_with_orders.columns, \"Semi-join should not add columns from right table\"\n",
    "assert 'amount' not in customers_with_orders.columns, \"Semi-join should not add columns from right table\"\n",
    "assert 'order_date' not in customers_with_orders.columns, \"Semi-join should not add columns from right table\"\n",
    "\n",
    "print(\"\\n✓ Basic semi-join working correctly!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11c17e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate duplicate elimination in semi-joins\n",
    "print(\"=== Demonstrating Duplicate Elimination ===\")\n",
    "\n",
    "# Create a DataFrame with duplicates\n",
    "customers_with_duplicates = DataFrame({\n",
    "    'customer_id': ['C001', 'C001', 'C003', 'C003', 'C007'],  # Duplicates\n",
    "    'region': ['North', 'North', 'South', 'South', 'West'],\n",
    "    'value': [100, 100, 200, 200, 300]\n",
    "}, name=\"customers_dup\")\n",
    "\n",
    "print(\"DataFrame with duplicates:\")\n",
    "display(customers_with_duplicates.to_pandas())\n",
    "\n",
    "# Semi-join automatically eliminates duplicates\n",
    "unique_customers_with_orders = customers_with_duplicates.exists(orders, on='customer_id')\n",
    "\n",
    "print(\"\\nAfter semi-join (duplicates eliminated):\")\n",
    "display(unique_customers_with_orders.to_pandas())\n",
    "print(f\"Original rows: {len(customers_with_duplicates)}, after semi-join: {len(unique_customers_with_orders)}\")\n",
    "\n",
    "print(\"\\n✓ Duplicate elimination working correctly!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a8529b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-column semi-join example\n",
    "print(\"=== Multi-Column Semi-Join ===\")\n",
    "\n",
    "# Create DataFrames for multi-column join\n",
    "users_data = {\n",
    "    'user_id': ['U001', 'U002', 'U003', 'U004', 'U005'],\n",
    "    'region': ['US', 'US', 'EU', 'EU', 'ASIA'],\n",
    "    'active': [True, False, True, True, False],\n",
    "    'subscription': ['premium', 'basic', 'premium', 'free', 'premium']\n",
    "}\n",
    "users = DataFrame(users_data, name=\"users\")\n",
    "\n",
    "sessions_data = {\n",
    "    'session_id': ['S001', 'S002', 'S003', 'S004'],\n",
    "    'user_id': ['U001', 'U003', 'U001', 'U004'],\n",
    "    'region': ['US', 'EU', 'US', 'EU'],\n",
    "    'duration': jnp.array([30.0, 45.0, 60.0, 25.0])\n",
    "}\n",
    "sessions = DataFrame(sessions_data, name=\"sessions\")\n",
    "\n",
    "print(\"Users DataFrame:\")\n",
    "display(users.to_pandas())\n",
    "print(\"\\nSessions DataFrame:\")\n",
    "display(sessions.to_pandas())\n",
    "\n",
    "# Find users who have sessions in their region\n",
    "active_users = users.exists(sessions, on=['user_id', 'region'])\n",
    "\n",
    "print(\"\\nUsers with sessions in their region:\")\n",
    "display(active_users.to_pandas())\n",
    "\n",
    "print(\"\\n✓ Multi-column semi-join working correctly!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb6564d",
   "metadata": {},
   "source": [
    "## 4. Test Semi-Join with JAX Arrays\n",
    "\n",
    "Test the exists() method with JAX arrays to ensure compatibility with JAX computational graphs and JIT compilation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f295f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with pure JAX arrays\n",
    "print(\"=== Testing with JAX Arrays ===\")\n",
    "\n",
    "jax_left = DataFrame({\n",
    "    'id': ['A', 'B', 'C', 'D', 'E'],\n",
    "    'values': jnp.array([1.0, 2.0, 3.0, 4.0, 5.0]),\n",
    "    'scores': jnp.array([10.5, 20.3, 30.1, 40.7, 50.9])\n",
    "}, name=\"jax_left\")\n",
    "\n",
    "jax_right = DataFrame({\n",
    "    'id': ['B', 'D', 'F', 'G'],\n",
    "    'other_data': jnp.array([100.0, 200.0, 300.0, 400.0])\n",
    "}, name=\"jax_right\")\n",
    "\n",
    "print(\"Left JAX DataFrame:\")\n",
    "display(jax_left.to_pandas())\n",
    "print(\"\\nRight JAX DataFrame:\")\n",
    "display(jax_right.to_pandas())\n",
    "\n",
    "# Perform semi-join\n",
    "jax_result = jax_left.exists(jax_right, on='id')\n",
    "\n",
    "print(\"\\nJAX Semi-Join Result:\")\n",
    "display(jax_result.to_pandas())\n",
    "print(f\"\\nResult column types: {jax_result.column_types}\")\n",
    "\n",
    "# Verify JAX array types are preserved\n",
    "assert jax_result.column_types['values'] == 'jax_array', \"JAX array type should be preserved\"\n",
    "assert jax_result.column_types['scores'] == 'jax_array', \"JAX array type should be preserved\"\n",
    "\n",
    "print(\"\\n✓ JAX array semi-join working correctly!\")\n",
    "print(\"✓ JAX array types preserved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8315405",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test JAX compilation compatibility\n",
    "from jax import jit\n",
    "\n",
    "print(\"=== Testing JAX JIT Compatibility ===\")\n",
    "\n",
    "def process_with_semi_join(left_values, right_values):\n",
    "    \"\"\"Function that uses semi-join in a JAX computational graph.\"\"\"\n",
    "    # Create temporary DataFrames\n",
    "    left_df = DataFrame({\n",
    "        'id': ['A', 'B', 'C'],\n",
    "        'values': left_values\n",
    "    })\n",
    "    \n",
    "    right_df = DataFrame({\n",
    "        'id': ['B', 'C', 'D'],\n",
    "        'other': right_values\n",
    "    })\n",
    "    \n",
    "    # Perform semi-join\n",
    "    result = left_df.exists(right_df, on='id')\n",
    "    \n",
    "    # Return JAX array for further computation\n",
    "    return result['values']\n",
    "\n",
    "# Test the function\n",
    "left_vals = jnp.array([1.0, 2.0, 3.0])\n",
    "right_vals = jnp.array([10.0, 20.0, 30.0])\n",
    "\n",
    "result_values = process_with_semi_join(left_vals, right_vals)\n",
    "print(f\"Semi-join result values: {result_values}\")\n",
    "print(f\"Result shape: {result_values.shape}\")\n",
    "print(f\"Result type: {type(result_values)}\")\n",
    "\n",
    "# Test that we can use this in further JAX operations\n",
    "final_result = jnp.sum(result_values ** 2)\n",
    "print(f\"\\nFurther JAX computation (sum of squares): {final_result}\")\n",
    "\n",
    "print(\"\\n✓ JAX computational graph compatibility verified!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a398ef",
   "metadata": {},
   "source": [
    "## 5. Compare Performance: exists() vs Traditional Joins\n",
    "\n",
    "Compare the performance and memory usage of semi-joins using exists() versus traditional inner joins followed by column selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0602cc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create larger DataFrames for performance testing\n",
    "print(\"=== Performance Comparison: exists() vs join() ===\")\n",
    "\n",
    "# Create larger test data\n",
    "n_left = 10000\n",
    "n_right = 5000\n",
    "\n",
    "large_left = DataFrame({\n",
    "    'id': [f'ID_{i:05d}' for i in range(n_left)],\n",
    "    'value1': np.random.randn(n_left),\n",
    "    'value2': jnp.array(np.random.randn(n_left)),\n",
    "    'category': [f'Cat_{i % 100}' for i in range(n_left)]\n",
    "}, name=\"large_left\")\n",
    "\n",
    "# Create right table with only partial overlap\n",
    "right_ids = [f'ID_{i:05d}' for i in range(0, n_left, 3)]  # Every 3rd ID\n",
    "large_right = DataFrame({\n",
    "    'id': right_ids,\n",
    "    'extra_data': np.random.randn(len(right_ids)),\n",
    "    'flag': [True] * len(right_ids)\n",
    "}, name=\"large_right\")\n",
    "\n",
    "print(f\"Left DataFrame: {large_left.shape}\")\n",
    "print(f\"Right DataFrame: {large_right.shape}\")\n",
    "print(f\"Expected result size: ~{len(right_ids)} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76be17aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 1: Using exists() (semi-join)\n",
    "print(\"\\n=== Method 1: exists() Semi-Join ===\")\n",
    "start_time = time.time()\n",
    "\n",
    "result_exists = large_left.exists(large_right, on='id')\n",
    "\n",
    "exists_time = time.time() - start_time\n",
    "print(f\"exists() time: {exists_time:.4f} seconds\")\n",
    "print(f\"Result shape: {result_exists.shape}\")\n",
    "print(f\"Result columns: {result_exists.columns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc5c583",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 2: Using traditional join() then column removal\n",
    "print(\"\\n=== Method 2: Traditional join() + Column Selection ===\")\n",
    "start_time = time.time()\n",
    "\n",
    "# Traditional approach: join then remove unwanted columns\n",
    "result_join = large_left.join(large_right, on='id', source='flag')\n",
    "# Remove the added column to match semi-join result\n",
    "result_join_cleaned = result_join.remove_column('large_right/flag')\n",
    "\n",
    "join_time = time.time() - start_time\n",
    "print(f\"join() + cleanup time: {join_time:.4f} seconds\")\n",
    "print(f\"Result shape: {result_join_cleaned.shape}\")\n",
    "print(f\"Result columns: {result_join_cleaned.columns}\")\n",
    "\n",
    "# Verify results are equivalent\n",
    "print(f\"\\n=== Results Comparison ===\")\n",
    "print(f\"exists() is {join_time/exists_time:.2f}x faster than join() + cleanup\")\n",
    "print(f\"Results are equivalent: {result_exists.shape == result_join_cleaned.shape}\")\n",
    "\n",
    "# Check if the actual data is the same (should be, since both filter the same rows)\n",
    "exists_ids = set(result_exists['id'])\n",
    "join_ids = set(result_join_cleaned['id'])\n",
    "print(f\"Same filtered IDs: {exists_ids == join_ids}\")\n",
    "\n",
    "print(\"\\n✓ Performance comparison completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7550e1",
   "metadata": {},
   "source": [
    "## 6. Test Edge Cases and Error Handling\n",
    "\n",
    "Test edge cases including empty DataFrames, non-existent join keys, and various data type combinations to ensure robust error handling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44da880e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Testing Edge Cases ===\")\n",
    "\n",
    "# Test 1: Empty result (no matches)\n",
    "print(\"\\n1. Testing with no matches:\")\n",
    "no_match_left = DataFrame({\n",
    "    'id': ['X', 'Y', 'Z'],\n",
    "    'value': [1, 2, 3]\n",
    "})\n",
    "\n",
    "no_match_right = DataFrame({\n",
    "    'id': ['A', 'B', 'C'],\n",
    "    'other': [10, 20, 30]\n",
    "})\n",
    "\n",
    "empty_result = no_match_left.exists(no_match_right, on='id')\n",
    "print(f\"Empty result shape: {empty_result.shape}\")\n",
    "print(f\"Empty result columns preserved: {empty_result.columns == no_match_left.columns}\")\n",
    "assert len(empty_result) == 0, \"Should return empty DataFrame\"\n",
    "print(\"✓ Empty result case works correctly\")\n",
    "\n",
    "# Test 2: Empty input DataFrames\n",
    "print(\"\\n2. Testing with empty left DataFrame:\")\n",
    "empty_left = DataFrame({'id': [], 'value': []}, name=\"empty_left\")\n",
    "non_empty_right = DataFrame({'id': ['A'], 'other': [1]}, name=\"non_empty_right\")\n",
    "\n",
    "result_empty_left = empty_left.exists(non_empty_right, on='id')\n",
    "print(f\"Result with empty left: {result_empty_left.shape}\")\n",
    "assert len(result_empty_left) == 0, \"Empty left should return empty result\"\n",
    "print(\"✓ Empty left DataFrame case works correctly\")\n",
    "\n",
    "print(\"\\n3. Testing with empty right DataFrame:\")\n",
    "non_empty_left = DataFrame({'id': ['A'], 'value': [1]}, name=\"non_empty_left\")\n",
    "empty_right = DataFrame({'id': [], 'other': []}, name=\"empty_right\")\n",
    "\n",
    "result_empty_right = non_empty_left.exists(empty_right, on='id')\n",
    "print(f\"Result with empty right: {result_empty_right.shape}\")\n",
    "assert len(result_empty_right) == 0, \"Empty right should return empty result\"\n",
    "print(\"✓ Empty right DataFrame case works correctly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87cfab43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test error conditions\n",
    "print(\"\\n=== Testing Error Conditions ===\")\n",
    "\n",
    "test_left = DataFrame({\n",
    "    'id': ['A', 'B'],\n",
    "    'value': [1, 2]\n",
    "})\n",
    "\n",
    "test_right = DataFrame({\n",
    "    'other_id': ['A', 'B'],\n",
    "    'other_value': [10, 20]\n",
    "})\n",
    "\n",
    "# Test 1: Missing column in left DataFrame\n",
    "print(\"\\n1. Testing missing column in left DataFrame:\")\n",
    "try:\n",
    "    test_left.exists(test_right, on='missing_column')\n",
    "    print(\"❌ Should have raised ValueError\")\n",
    "except ValueError as e:\n",
    "    print(f\"✓ Correctly raised ValueError: {e}\")\n",
    "\n",
    "# Test 2: Missing column in right DataFrame\n",
    "print(\"\\n2. Testing missing column in right DataFrame:\")\n",
    "try:\n",
    "    test_left.exists(test_right, on='id')  # 'id' exists in left but not right\n",
    "    print(\"❌ Should have raised ValueError\")\n",
    "except ValueError as e:\n",
    "    print(f\"✓ Correctly raised ValueError: {e}\")\n",
    "\n",
    "# Test 3: Multi-column with missing column\n",
    "print(\"\\n3. Testing multi-column with missing column:\")\n",
    "try:\n",
    "    test_left.exists(test_right, on=['id', 'missing'])\n",
    "    print(\"❌ Should have raised ValueError\")\n",
    "except ValueError as e:\n",
    "    print(f\"✓ Correctly raised ValueError: {e}\")\n",
    "\n",
    "print(\"\\n✓ All error conditions handled correctly!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e4cbef",
   "metadata": {},
   "source": [
    "## 7. Demonstrate Real-World Use Cases\n",
    "\n",
    "Show practical applications of semi-joins such as filtering samples based on treatment criteria, finding observations that have corresponding assay data, and other scientific data analysis scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb0d619",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Real-World Use Case 1: Clinical Trial Data ===\")\n",
    "\n",
    "# Create clinical trial datasets\n",
    "patients = DataFrame({\n",
    "    'patient_id': [f'P{i:03d}' for i in range(1, 21)],\n",
    "    'age': np.random.randint(18, 80, 20),\n",
    "    'gender': np.random.choice(['M', 'F'], 20),\n",
    "    'baseline_score': jnp.array(np.random.normal(50, 10, 20)),\n",
    "    'enrollment_date': ['2024-01-01'] * 20\n",
    "}, name=\"patients\")\n",
    "\n",
    "# Not all patients completed the study\n",
    "completed_patients = DataFrame({\n",
    "    'patient_id': [f'P{i:03d}' for i in [1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 2, 4]],  # 12 completed\n",
    "    'completion_date': ['2024-06-01'] * 12,\n",
    "    'final_score': jnp.array(np.random.normal(60, 15, 12))\n",
    "}, name=\"completed\")\n",
    "\n",
    "# Find patients who completed the study\n",
    "completers = patients.exists(completed_patients, on='patient_id')\n",
    "\n",
    "print(\"All enrolled patients:\")\n",
    "display(patients.to_pandas().head())\n",
    "print(f\"\\nTotal enrolled: {len(patients)}\")\n",
    "\n",
    "print(\"\\nPatients who completed the study:\")\n",
    "display(completers.to_pandas())\n",
    "print(f\"\\nCompletion rate: {len(completers)}/{len(patients)} ({100*len(completers)/len(patients):.1f}%)\")\n",
    "\n",
    "# Analyze completion by demographics\n",
    "completer_demographics = completers.to_pandas()\n",
    "print(f\"\\nCompleter demographics:\")\n",
    "print(f\"Average age of completers: {completer_demographics['age'].mean():.1f}\")\n",
    "print(f\"Gender distribution: {completer_demographics['gender'].value_counts().to_dict()}\")\n",
    "print(f\"Average baseline score: {completer_demographics['baseline_score'].mean():.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7fe94c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== Real-World Use Case 2: Laboratory Data Analysis ===\")\n",
    "\n",
    "# Create laboratory sample tracking system\n",
    "samples = DataFrame({\n",
    "    'sample_id': [f'S{i:04d}' for i in range(1, 101)],\n",
    "    'patient_id': [f'PT{i:03d}' for i in np.random.randint(1, 51, 100)],\n",
    "    'collection_date': ['2024-01-01'] * 100,\n",
    "    'sample_type': np.random.choice(['blood', 'urine', 'tissue'], 100),\n",
    "    'volume_ml': jnp.array(np.random.uniform(1.0, 10.0, 100))\n",
    "}, name=\"samples\")\n",
    "\n",
    "# Only some samples have been processed through specific assays\n",
    "assay_results = DataFrame({\n",
    "    'sample_id': [f'S{i:04d}' for i in [1, 5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70]],\n",
    "    'assay_type': ['protein_analysis'] * 15,\n",
    "    'result_value': jnp.array(np.random.normal(100, 20, 15)),\n",
    "    'processing_date': ['2024-01-15'] * 15\n",
    "}, name=\"assay_results\")\n",
    "\n",
    "quality_control = DataFrame({\n",
    "    'sample_id': [f'S{i:04d}' for i in [2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30]],\n",
    "    'qc_status': ['passed'] * 15,\n",
    "    'qc_date': ['2024-01-10'] * 15\n",
    "}, name=\"quality_control\")\n",
    "\n",
    "print(\"Laboratory Analysis Pipeline:\")\n",
    "print(f\"Total samples collected: {len(samples)}\")\n",
    "print(f\"Samples with assay results: {len(assay_results)}\")\n",
    "print(f\"Samples that passed QC: {len(quality_control)}\")\n",
    "\n",
    "# Find samples that have both QC and assay data\n",
    "qc_passed_samples = samples.exists(quality_control, on='sample_id')\n",
    "assayed_samples = samples.exists(assay_results, on='sample_id')\n",
    "fully_processed_samples = qc_passed_samples.exists(assay_results, on='sample_id')\n",
    "\n",
    "print(f\"\\nSamples that passed QC: {len(qc_passed_samples)}\")\n",
    "print(f\"Samples with assay data: {len(assayed_samples)}\")\n",
    "print(f\"Samples both QC'd and assayed: {len(fully_processed_samples)}\")\n",
    "\n",
    "print(\"\\nFully processed samples:\")\n",
    "display(fully_processed_samples.to_pandas())\n",
    "\n",
    "# Analyze by sample type\n",
    "processed_by_type = fully_processed_samples.to_pandas()['sample_type'].value_counts()\n",
    "print(f\"\\nProcessed samples by type: {processed_by_type.to_dict()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdbdc18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== Real-World Use Case 3: E-commerce Customer Analytics ===\")\n",
    "\n",
    "# Create e-commerce customer analysis scenario\n",
    "all_customers = DataFrame({\n",
    "    'customer_id': [f'CUST{i:05d}' for i in range(1, 1001)],\n",
    "    'registration_date': ['2023-01-01'] * 1000,\n",
    "    'country': np.random.choice(['US', 'UK', 'DE', 'FR', 'CA'], 1000),\n",
    "    'age_group': np.random.choice(['18-25', '26-35', '36-45', '46-55', '55+'], 1000),\n",
    "    'email_verified': np.random.choice([True, False], 1000, p=[0.8, 0.2])\n",
    "}, name=\"all_customers\")\n",
    "\n",
    "# Recent purchases (last 30 days)\n",
    "recent_purchases = DataFrame({\n",
    "    'customer_id': [f'CUST{i:05d}' for i in np.random.choice(range(1, 1001), 150, replace=False)],\n",
    "    'purchase_amount': jnp.array(np.random.exponential(50, 150)),\n",
    "    'purchase_date': ['2024-01-01'] * 150\n",
    "}, name=\"recent_purchases\")\n",
    "\n",
    "# Email campaign engagement\n",
    "email_engaged = DataFrame({\n",
    "    'customer_id': [f'CUST{i:05d}' for i in np.random.choice(range(1, 1001), 200, replace=False)],\n",
    "    'email_opened': [True] * 200,\n",
    "    'engagement_date': ['2024-01-15'] * 200\n",
    "}, name=\"email_engaged\")\n",
    "\n",
    "# Mobile app users\n",
    "mobile_users = DataFrame({\n",
    "    'customer_id': [f'CUST{i:05d}' for i in np.random.choice(range(1, 1001), 300, replace=False)],\n",
    "    'app_installed': [True] * 300,\n",
    "    'last_app_use': ['2024-01-20'] * 300\n",
    "}, name=\"mobile_users\")\n",
    "\n",
    "print(\"E-commerce Customer Segmentation:\")\n",
    "print(f\"Total customers: {len(all_customers)}\")\n",
    "print(f\"Recent purchasers: {len(recent_purchases)}\")\n",
    "print(f\"Email engaged: {len(email_engaged)}\")\n",
    "print(f\"Mobile app users: {len(mobile_users)}\")\n",
    "\n",
    "# Segment customers using semi-joins\n",
    "active_buyers = all_customers.exists(recent_purchases, on='customer_id')\n",
    "email_responsive = all_customers.exists(email_engaged, on='customer_id')\n",
    "mobile_engaged = all_customers.exists(mobile_users, on='customer_id')\n",
    "\n",
    "# High-value segment: customers who are active across all channels\n",
    "high_value_customers = active_buyers.exists(email_engaged, on='customer_id').exists(mobile_users, on='customer_id')\n",
    "\n",
    "print(f\"\\nCustomer Segments:\")\n",
    "print(f\"Active buyers: {len(active_buyers)} ({100*len(active_buyers)/len(all_customers):.1f}%)\")\n",
    "print(f\"Email responsive: {len(email_responsive)} ({100*len(email_responsive)/len(all_customers):.1f}%)\")\n",
    "print(f\"Mobile engaged: {len(mobile_engaged)} ({100*len(mobile_engaged)/len(all_customers):.1f}%)\")\n",
    "print(f\"High-value (all channels): {len(high_value_customers)} ({100*len(high_value_customers)/len(all_customers):.1f}%)\")\n",
    "\n",
    "# Analyze high-value segment\n",
    "hv_analysis = high_value_customers.to_pandas()\n",
    "print(f\"\\nHigh-Value Customer Analysis:\")\n",
    "print(f\"Country distribution: {hv_analysis['country'].value_counts().to_dict()}\")\n",
    "print(f\"Age group distribution: {hv_analysis['age_group'].value_counts().to_dict()}\")\n",
    "print(f\"Email verification rate: {100*hv_analysis['email_verified'].mean():.1f}%\")\n",
    "\n",
    "print(\"\\n✓ E-commerce customer segmentation completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38380f5a",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "The `exists()` method provides efficient semi-join functionality that:\n",
    "\n",
    "1. **Filters rows** based on existence of matches in another DataFrame\n",
    "2. **Preserves original structure** - only returns columns from the left table\n",
    "3. **Eliminates duplicates** automatically\n",
    "4. **Supports multi-column joins** for complex key relationships\n",
    "5. **Maintains JAX compatibility** for computational graphs\n",
    "6. **Handles mixed data types** (lists, NumPy arrays, JAX arrays)\n",
    "7. **Provides better performance** than traditional join + column removal\n",
    "8. **Robust error handling** for edge cases\n",
    "\n",
    "### Key Benefits:\n",
    "- **Cleaner API**: Directly expresses the intent of filtering based on existence\n",
    "- **Performance**: Optimized for the semi-join operation without unnecessary column copying\n",
    "- **Memory efficiency**: Doesn't create intermediate DataFrames with unwanted columns\n",
    "- **Type safety**: Preserves original column types including JAX arrays\n",
    "- **Automatic deduplication**: No need to manually handle duplicates\n",
    "\n",
    "This makes the `exists()` method ideal for data analysis scenarios where you need to filter one dataset based on the presence of related records in another dataset."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
